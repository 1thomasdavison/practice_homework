#!/usr/bin/env python3
"""
ç¡å§¿å±•ç¤ºç³»ç»Ÿ - Flask Webåº”ç”¨ (MindSporeç‰ˆæœ¬)
æ”¯æŒäº”ç±»ç¡å§¿ï¼ˆä»°å§ã€ä¿¯å§ã€å·¦ä¾§å§ã€å³ä¾§å§ã€åå§¿ï¼‰çš„å‹åŠ›å›¾çƒ­åŠ›å›¾å±•ç¤º
ä½¿ç”¨MindSpore + Ascend AIå¤„ç†å™¨è¿›è¡Œæ¨ç†
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.font_manager as fm
import io
import base64
from flask import Flask, render_template, jsonify, request, send_from_directory
import glob
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

# å¯¼å…¥MindSporeç›¸å…³åº“
try:
    import mindspore
    import mindspore.nn as nn
    import mindspore.ops as ops
    from mindspore import Tensor
    from train_mindspore import SimpleCNN
    MINDSPORE_AVAILABLE = True
    print("âœ… MindSporeåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    MINDSPORE_AVAILABLE = False
    print(f"âš ï¸ MindSporeåº“å¯¼å…¥å¤±è´¥: {e}")
    print("âš ï¸ å°†ä½¿ç”¨CPUæ¨¡å¼è¿è¡Œï¼ˆå¦‚æœæœ‰PyTorchæ¨¡å‹ï¼‰")

# é…ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    # ç›´æ¥æŒ‡å®šå­—ä½“æ–‡ä»¶è·¯å¾„
    font_paths = [
        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc'
    ]
    
    # å°è¯•æ³¨å†Œå­—ä½“
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                fm.fontManager.addfont(font_path)
                print(f"âœ… æˆåŠŸæ³¨å†Œå­—ä½“: {font_path}")
            except Exception as e:
                print(f"âš ï¸ æ³¨å†Œå­—ä½“å¤±è´¥ {font_path}: {e}")
    
    # è®¾ç½®matplotlibå­—ä½“é…ç½®
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'WenQuanYi Micro Hei', 'Arial Unicode MS', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # å¼ºåˆ¶é‡å»ºå­—ä½“ç¼“å­˜
    try:
        fm._rebuild()
        print("âœ… å­—ä½“ç¼“å­˜é‡å»ºå®Œæˆ")
    except:
        print("âš ï¸ å­—ä½“ç¼“å­˜é‡å»ºå¤±è´¥ï¼Œä½¿ç”¨ç°æœ‰ç¼“å­˜")
    
    print(f"âœ… ä¸­æ–‡å­—ä½“é…ç½®å®Œæˆ")
    
# åˆå§‹åŒ–ä¸­æ–‡å­—ä½“é…ç½®
setup_chinese_font()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from dataloader.get_data_display import get_person_folders, load_pressure_data, compute_average_pressure_map

app = Flask(__name__)

# å…¨å±€å˜é‡
dataset = {}
person_list = []
model = None
model_type = "æœªåŠ è½½"

label_names = {
    1: "Supine",
    2: "Prone", 
    3: "Left Side",
    4: "Right Side",
    5: "Sitting"
}

label_names_cn = {
    1: "ä»°å§",
    2: "ä¿¯å§", 
    3: "å·¦ä¾§å§",
    4: "å³ä¾§å§",
    5: "åå§¿"
}

def load_mindspore_model():
    """åŠ è½½MindSporeæ¨¡å‹"""
    global model, model_type
    
    if not MINDSPORE_AVAILABLE:
        print("âš ï¸ MindSporeä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½MindSporeæ¨¡å‹")
        return False
    
    model_path = "best_model_converted.ckpt"
    
    if not os.path.exists(model_path):
        print(f"âš ï¸ MindSporeæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    try:
        # è®¾ç½®MindSporeä¸Šä¸‹æ–‡
        mindspore.set_context(
            mode=mindspore.PYNATIVE_MODE,
            device_target="Ascend",
            device_id=0
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = SimpleCNN(num_classes=4)
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        param_dict = mindspore.load_checkpoint(model_path)
        mindspore.load_param_into_net(model, param_dict)
        model.set_train(False)
        
        model_type = "MindSpore + Ascend"
        print(f"âœ… MindSporeæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        return True
        
    except Exception as e:
        print(f"âŒ MindSporeæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        model = None
        model_type = "æœªåŠ è½½"
        return False

def load_pytorch_model():
    """å¤‡ç”¨ï¼šåŠ è½½PyTorchæ¨¡å‹ï¼ˆå¦‚æœMindSporeä¸å¯ç”¨ï¼‰"""
    global model, model_type
    
    try:
        import torch
        from train import SimpleCNN as PyTorchSimpleCNN
        
        model_path = "best_model.pth"
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ PyTorchæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        # åˆ›å»ºæ¨¡å‹
        model = PyTorchSimpleCNN(num_classes=4)
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        
        model_type = "PyTorch + CPU (å¤‡ç”¨)"
        print(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        return True
        
    except ImportError:
        print("âš ï¸ PyTorchä¹Ÿä¸å¯ç”¨")
        return False
    except Exception as e:
        print(f"âŒ PyTorchæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return False

def predict_with_mindspore(pressure_data):
    """ä½¿ç”¨MindSporeæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    if not MINDSPORE_AVAILABLE or model is None:
        return None
    
    try:
        # è½¬æ¢æ•°æ®ä¸ºMindSpore Tensor
        tensor_data = Tensor(pressure_data, mindspore.float32)
        tensor_data = ops.expand_dims(tensor_data, 0)  # batchç»´åº¦
        tensor_data = ops.expand_dims(tensor_data, 0)  # channelç»´åº¦
        
        # æ¨¡å‹æ¨ç†
        outputs = model(tensor_data)
        
        # è®¡ç®—æ¦‚ç‡
        softmax = nn.Softmax(axis=1)
        probabilities = softmax(outputs)
        
        # è·å–é¢„æµ‹ç»“æœ
        confidence = ops.max(probabilities, axis=1)[0]
        predicted = ops.argmax(probabilities, axis=1)
        
        return {
            'predicted_label': predicted.asnumpy().item(),
            'confidence': confidence.asnumpy().item(),
            'probabilities': probabilities.asnumpy()[0].tolist()
        }
        
    except Exception as e:
        print(f"MindSporeé¢„æµ‹é”™è¯¯: {str(e)}")
        return None

def predict_with_pytorch(pressure_data):
    """ä½¿ç”¨PyTorchæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆå¤‡ç”¨ï¼‰"""
    try:
        import torch
        
        if model is None:
            return None
        
        # è½¬æ¢æ•°æ®
        tensor_data = torch.FloatTensor(pressure_data).unsqueeze(0).unsqueeze(0)
        
        with torch.no_grad():
            outputs = model(tensor_data)
            probabilities = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
        return {
            'predicted_label': predicted.item(),
            'confidence': confidence.item(),
            'probabilities': probabilities[0].tolist()
        }
        
    except Exception as e:
        print(f"PyTorché¢„æµ‹é”™è¯¯: {str(e)}")
        return None

def predict_posture(pressure_data):
    """ç»Ÿä¸€çš„é¢„æµ‹æ¥å£"""
    if model_type.startswith("MindSpore"):
        return predict_with_mindspore(pressure_data)
    elif model_type.startswith("PyTorch"):
        return predict_with_pytorch(pressure_data)
    else:
        return None

def get_extended_label_mapping():
    """è·å–æ‰©å±•çš„æ ‡ç­¾æ˜ å°„å…³ç³»ï¼ŒåŒ…æ‹¬åå§¿"""
    return {
        1: 1,  # æ ‡å‡†ä»°å§ -> ä»°å§
        2: 2,  # æ ‡å‡†ä¿¯å§ -> ä¿¯å§  
        3: 3,  # å·¦ä¾§å§ï¼ˆå¼¯è…¿) -> å·¦ä¾§å§
        4: 3,  # å·¦ä¾§å§ï¼ˆä¼¸è…¿) -> å·¦ä¾§å§
        5: 4,  # å³ä¾§å§ï¼ˆå¼¯è…¿) -> å³ä¾§å§
        6: 4,  # å³ä¾§å§ï¼ˆä¼¸è…¿) -> å³ä¾§å§
        7: 5,  # åå§¿ -> åå§¿
    }

def load_extended_dataset(data_root):
    """åŠ è½½åŒ…å«åå§¿çš„æ‰©å±•æ•°æ®é›†"""
    label_mapping = get_extended_label_mapping()
    person_folders = get_person_folders(data_root)
    
    # å¤„ç†sitæ–‡ä»¶å¤¹ä¸­çš„åå§¿æ•°æ®
    sit_folder = os.path.join(data_root, 'sit')
    
    all_data = {}
    
    print(f"æ­£åœ¨åŠ è½½ {len(person_folders)} ä¸ªç”¨æˆ·çš„æ•°æ®...")
    
    # å¤„ç†æ¯ä¸ªäººå‘˜çš„æ•°æ®
    for person_name in person_folders:
        person_folder_path = os.path.join(data_root, person_name)
        person_data = {}
        
        # æŸ¥æ‰¾è¯¥äººå‘˜çš„æ‰€æœ‰txtæ–‡ä»¶
        txt_files = glob.glob(os.path.join(person_folder_path, f"{person_name}_*.txt"))
        
        for txt_file in txt_files:
            filename = os.path.basename(txt_file)
            try:
                original_label = int(filename.split('_')[-1].split('.')[0])
            except ValueError:
                continue
            
            if original_label not in label_mapping:
                continue
            
            # åŠ è½½å‹åŠ›å›¾æ•°æ®
            frames = load_pressure_data(txt_file)
            if frames is None:
                continue
            
            # è®¡ç®—å¹³å‡å‹åŠ›å›¾
            avg_pressure_map = compute_average_pressure_map(frames)
            new_label = label_mapping[original_label]
            
            person_data[new_label] = avg_pressure_map.tolist()  # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        
        # æ£€æŸ¥sitæ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰è¯¥äººå‘˜çš„åå§¿æ•°æ®
        if os.path.exists(sit_folder):
            sit_files = glob.glob(os.path.join(sit_folder, f"{person_name}_*.txt"))
            for sit_file in sit_files:
                frames = load_pressure_data(sit_file)
                if frames is not None:
                    avg_pressure_map = compute_average_pressure_map(frames)
                    person_data[5] = avg_pressure_map.tolist()  # æ ‡ç­¾5ä¸ºåå§¿
                    break  # åªå–ç¬¬ä¸€ä¸ªåå§¿æ–‡ä»¶
        
        if person_data:  # åªæœ‰å½“æœ‰æ•°æ®æ—¶æ‰æ·»åŠ 
            all_data[person_name] = person_data
    
    return all_data, list(all_data.keys())

def create_heatmap_image(pressure_map, title="å‹åŠ›å›¾çƒ­åŠ›å›¾", show_prediction=False, prediction_info=None):
    """
    åˆ›å»ºå‹åŠ›å›¾çƒ­åŠ›å›¾å¹¶è¿”å›base64ç¼–ç çš„å›¾ç‰‡
    
    Args:
        pressure_map: å‹åŠ›å›¾æ•°æ® (40, 26)
        title: å›¾è¡¨æ ‡é¢˜
        show_prediction: æ˜¯å¦æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        prediction_info: é¢„æµ‹ä¿¡æ¯å­—å…¸
    
    Returns:
        base64ç¼–ç çš„å›¾ç‰‡å­—ç¬¦ä¸²
    """
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(pressure_map, list):
        pressure_map = np.array(pressure_map)
    
    # æ ¹æ®æ˜¯å¦æ˜¾ç¤ºé¢„æµ‹ç»“æœè°ƒæ•´å›¾ç‰‡å¤§å°
    if show_prediction and prediction_info:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # å·¦å›¾ï¼šçƒ­åŠ›å›¾
        im = ax1.imshow(pressure_map, cmap='hot', interpolation='bilinear', aspect='auto')
        ax1.set_title(title, fontsize=14, fontweight='bold')
        ax1.set_xlabel('Width Direction')
        ax1.set_ylabel('Length Direction')
        plt.colorbar(im, ax=ax1, shrink=0.8)
        
        # å³å›¾ï¼šé¢„æµ‹ç»“æœ
        predicted_label = prediction_info['predicted_label']
        confidence = prediction_info['confidence']
        probabilities = prediction_info['probabilities']
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœæ–‡æœ¬
        ax2.text(0.5, 0.7, f"é¢„æµ‹ç»“æœ: {label_names_cn[predicted_label + 1]}", 
                fontsize=16, fontweight='bold', ha='center', va='center')
        ax2.text(0.5, 0.6, f"ç½®ä¿¡åº¦: {confidence:.3f}", 
                fontsize=14, ha='center', va='center')
        ax2.text(0.5, 0.5, f"æ¨ç†å¼•æ“: {model_type}", 
                fontsize=12, ha='center', va='center', style='italic')
        
        # æ˜¾ç¤ºå„ç±»åˆ«æ¦‚ç‡
        label_names_list = ['ä»°å§', 'ä¿¯å§', 'å·¦ä¾§å§', 'å³ä¾§å§']
        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
        
        y_pos = 0.3
        for i, (name, prob) in enumerate(zip(label_names_list, probabilities)):
            color = colors[i] if i == predicted_label else 'gray'
            weight = 'bold' if i == predicted_label else 'normal'
            ax2.text(0.5, y_pos, f"{name}: {prob:.3f}", 
                    fontsize=10, ha='center', va='center', 
                    color=color, fontweight=weight)
            y_pos -= 0.04
        
        ax2.set_xlim(0, 1)
        ax2.set_ylim(0, 1)
        ax2.axis('off')
        ax2.set_title('AIé¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')
        
    else:
        # åªæ˜¾ç¤ºçƒ­åŠ›å›¾
        plt.figure(figsize=(12, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        im = plt.imshow(pressure_map, cmap='hot', interpolation='bilinear', aspect='auto')
        
        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Width Direction (Sensor Columns)', fontsize=12)
        plt.ylabel('Length Direction (Sensor Rows)', fontsize=12)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, shrink=0.8)
        cbar.set_label('Pressure Value', fontsize=12)
        
        # è®¾ç½®ç½‘æ ¼
        plt.grid(True, alpha=0.3)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜ä¸ºbase64å›¾ç‰‡
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png', dpi=100, bbox_inches='tight')
    img_buffer.seek(0)
    img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
    plt.close()  # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜
    
    return img_base64

def get_pressure_statistics(pressure_map):
    """è®¡ç®—å‹åŠ›å›¾ç»Ÿè®¡ä¿¡æ¯"""
    if isinstance(pressure_map, list):
        pressure_map = np.array(pressure_map)
    
    return {
        'max': float(np.max(pressure_map)),
        'min': float(np.min(pressure_map)),
        'mean': float(np.mean(pressure_map)),
        'std': float(np.std(pressure_map)),
        'shape': pressure_map.shape
    }

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('index.html', 
                         person_list=person_list,
                         label_names=label_names_cn,
                         model_type=model_type)

@app.route('/api/system_info')
def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    return jsonify({
        'model_type': model_type,
        'mindspore_available': MINDSPORE_AVAILABLE,
        'total_users': len(person_list),
        'framework': 'MindSpore' if model_type.startswith('MindSpore') else 'PyTorch'
    })

@app.route('/api/users')
def get_users():
    """è·å–æ‰€æœ‰ç”¨æˆ·åˆ—è¡¨"""
    return jsonify({
        'users': person_list,
        'total': len(person_list),
        'model_type': model_type
    })

@app.route('/api/user/<user_name>/postures')
def get_user_postures(user_name):
    """è·å–æŒ‡å®šç”¨æˆ·çš„å¯ç”¨ç¡å§¿"""
    if user_name not in dataset:
        return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    postures = list(dataset[user_name].keys())
    posture_info = {
        posture: label_names_cn[posture] 
        for posture in postures
    }
    
    return jsonify({
        'user': user_name,
        'postures': posture_info,
        'total': len(postures),
        'model_type': model_type
    })

@app.route('/api/heatmap/<user_name>/<int:posture_label>')
def get_heatmap(user_name, posture_label):
    """è·å–æŒ‡å®šç”¨æˆ·å’Œç¡å§¿çš„çƒ­åŠ›å›¾"""
    if user_name not in dataset:
        return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    if posture_label not in dataset[user_name]:
        return jsonify({'error': f'ç”¨æˆ· {user_name} æ²¡æœ‰ {label_names_cn.get(posture_label, "æœªçŸ¥")} çš„æ•°æ®'}), 404
    
    pressure_map = dataset[user_name][posture_label]
    title = f"{user_name} - {label_names[posture_label]} Pressure Map"
    
    # AIé¢„æµ‹
    prediction_info = None
    if model is not None:
        prediction_info = predict_posture(np.array(pressure_map))
    
    # ç”Ÿæˆçƒ­åŠ›å›¾ï¼ˆåŒ…å«é¢„æµ‹ç»“æœï¼‰
    show_prediction = prediction_info is not None
    img_base64 = create_heatmap_image(pressure_map, title, show_prediction, prediction_info)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = get_pressure_statistics(pressure_map)
    
    response_data = {
        'user': user_name,
        'posture': label_names_cn[posture_label], 
        'posture_label': posture_label,
        'image': img_base64,
        'statistics': stats,
        'model_type': model_type
    }
    
    # æ·»åŠ é¢„æµ‹ä¿¡æ¯
    if prediction_info:
        response_data['prediction'] = {
            'predicted_label': prediction_info['predicted_label'],
            'predicted_name': label_names_cn[prediction_info['predicted_label'] + 1],
            'confidence': prediction_info['confidence'],
            'probabilities': prediction_info['probabilities']
        }
    
    return jsonify(response_data)

@app.route('/api/compare/<user_name>')
def compare_postures(user_name):
    """æ¯”è¾ƒæŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰ç¡å§¿"""
    if user_name not in dataset:
        return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    user_data = dataset[user_name]
    available_postures = list(user_data.keys())
    n_postures = len(available_postures)
    
    if n_postures == 0:
        return jsonify({'error': 'ç”¨æˆ·æ²¡æœ‰å¯æ¯”è¾ƒçš„ç¡å§¿æ•°æ®'}), 404
    
    # åˆ›å»ºæ¯”è¾ƒå›¾
    cols = min(3, n_postures)
    rows = (n_postures + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
    
    if n_postures == 1:
        axes = [axes]
    elif rows == 1:
        axes = axes if hasattr(axes, '__iter__') else [axes]
    else:
        axes = axes.flatten()
    
    for i, posture_label in enumerate(available_postures):
        pressure_map = np.array(user_data[posture_label])
        
        im = axes[i].imshow(pressure_map, cmap='hot', interpolation='bilinear', aspect='auto')
        
        # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾é¿å…å­—ä½“é—®é¢˜
        posture_names_en = {
            1: "Supine", 2: "Prone", 3: "Left Side", 4: "Right Side", 5: "Sitting"
        }
        axes[i].set_title(f"{posture_names_en.get(posture_label, 'Unknown')}", fontweight='bold')
        axes[i].set_xlabel('Width')
        axes[i].set_ylabel('Length')
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im, ax=axes[i], shrink=0.8)
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(n_postures, len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle(f"{user_name} - Posture Comparison ({model_type})", fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜ä¸ºbase64å›¾ç‰‡
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png', dpi=100, bbox_inches='tight')
    img_buffer.seek(0)
    img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
    plt.close()
    
    return jsonify({
        'user': user_name,
        'postures': [label_names_cn[p] for p in available_postures],
        'image': img_base64,
        'total_postures': n_postures,
        'model_type': model_type
    })

@app.route('/api/statistics')
def get_statistics():
    """è·å–æ•´ä½“ç»Ÿè®¡ä¿¡æ¯"""
    posture_stats = {}
    
    for person, data in dataset.items():
        for label in data.keys():
            if label not in posture_stats:
                posture_stats[label] = 0
            posture_stats[label] += 1
    
    return jsonify({
        'total_users': len(person_list),
        'total_samples': sum(posture_stats.values()),
        'posture_stats': {
            label_names_cn[label]: count 
            for label, count in sorted(posture_stats.items())
        },
        'model_type': model_type,
        'framework': 'MindSpore' if model_type.startswith('MindSpore') else 'PyTorch'
    })

def initialize_app():
    """åˆå§‹åŒ–åº”ç”¨æ•°æ®"""
    global dataset, person_list
    
    data_root = "data/text_data"
    print("æ­£åœ¨åˆå§‹åŒ–ç¡å§¿å±•ç¤ºç³»ç»Ÿ (MindSporeç‰ˆæœ¬)...")
    
    # ä¼˜å…ˆå°è¯•åŠ è½½MindSporeæ¨¡å‹
    model_loaded = False
    if MINDSPORE_AVAILABLE:
        print("å°è¯•åŠ è½½MindSporeæ¨¡å‹...")
        model_loaded = load_mindspore_model()
    
    # å¦‚æœMindSporeæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•PyTorchæ¨¡å‹ä½œä¸ºå¤‡ç”¨
    if not model_loaded:
        print("å°è¯•åŠ è½½PyTorchæ¨¡å‹ä½œä¸ºå¤‡ç”¨...")
        model_loaded = load_pytorch_model()
    
    if not model_loaded:
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œå°†åœ¨æ— AIé¢„æµ‹åŠŸèƒ½çš„æ¨¡å¼ä¸‹è¿è¡Œ")
        global model_type
        model_type = "æ— å¯ç”¨æ¨¡å‹"
    
    try:
        dataset, person_list = load_extended_dataset(data_root)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼å…±åŠ è½½ {len(person_list)} ä¸ªç”¨æˆ·çš„æ•°æ®")
        print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_type}")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return False

if __name__ == '__main__':
    # åˆå§‹åŒ–æ•°æ®
    if initialize_app():
        print("ğŸš€ å¯åŠ¨ç¡å§¿å±•ç¤ºç³»ç»Ÿ (MindSporeç‰ˆæœ¬)...")
        print("ğŸ“¡ è®¿é—®åœ°å€: http://localhost:5000")
        print(f"ğŸ§  AIæ¨ç†å¼•æ“: {model_type}")
        app.run(host='0.0.0.0', port=5000, debug=True)
    else:
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨")
